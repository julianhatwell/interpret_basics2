{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prologue\n",
    "Prepare the notebook for inline plotting<br>\n",
    "Load required libraries<br>\n",
    "Create custom functions<br>\n",
    "Load and preprocess data<br>\n",
    "Train a random forest using previously optimized/tuned hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# experimental script\n",
    "import pickle\n",
    "import forest_surveyor.datasets as ds\n",
    "from forest_surveyor.routines import experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING NEW DATA SET.\n",
      "\n",
      "Finding best paramaters for Random Forest. Checking for prior tuning paramters.\n",
      "\n",
      "Using existing params file. To re-tune, delete file at whiteboxing\\rcdv_samp_pickles\\params.json\n",
      "\n",
      "Best OOB Cohen's Kappa during tuning: 0.8748\n",
      "Best parameters: {'min_samples_leaf': 1, 'max_depth': 16, 'n_estimators': 1500}\n",
      "\n",
      "Training a random forest model using best parameters... (please wait)\n",
      "\n",
      "Done\n",
      "\n",
      "No encoder was provided. An encoder is required if not all the data is numerical.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'recid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a9473293b717>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m                     \u001b[0malpha_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha_scores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[0mwhich_trees\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'majority'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                     \u001b[0meval_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                      \u001b[1;31m#, output_results=True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                         )\n",
      "\u001b[1;32mC:\\dev\\study\\python\\interpret_basics2\\forest_surveyor\\routines.py\u001b[0m in \u001b[0;36mexperiment\u001b[1;34m(get_dataset, n_instances, n_batches, support_paths, alpha_paths, alpha_scores, which_trees, greedy, eval_model)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         cm, prfs = evaluate_model(prediction_model=enc_rf, X=tt['X_test'], y=tt['y_test'],\n\u001b[1;32m--> 359\u001b[1;33m                      \u001b[0mclass_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m                      plot_cm=True, plot_cm_norm=True)\n\u001b[0;32m    361\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\study\\python\\interpret_basics2\\forest_surveyor\\structures.py\u001b[0m in \u001b[0;36mget_label\u001b[1;34m(self, col, label)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# a function to return any label from a code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;31m# train test splitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'recid'"
     ]
    }
   ],
   "source": [
    "alpha_scores = 0.75\n",
    "for dataset in [\n",
    "#                 ds.accident_small_samp_data,\n",
    "#                 ds.adult_small_samp_data,\n",
    "#                 ds.bankmark_samp_data,\n",
    "#                 ds.car_data,\n",
    "#                 ds.cardiotography_data,\n",
    "#                 ds.credit_data,\n",
    "#                 ds.german_data,\n",
    "#                 ds.lending_tiny_samp_data,\n",
    "#                 ds.nursery_samp_data,\n",
    "                ds.rcdv_samp_data\n",
    "               ]:\n",
    "\n",
    "# for dataset in [ds.rcdv_samp_data]:\n",
    "    rule_acc, results, output_df = experiment(dataset,\n",
    "                    n_instances=5,\n",
    "                    n_batches=1,\n",
    "                    support_paths=0.05,\n",
    "                    alpha_paths=0.6,\n",
    "                    alpha_scores=alpha_scores,\n",
    "                    which_trees='majority',\n",
    "                    eval_model=True\n",
    "                     #, output_results=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Local Explanations\n",
    "## Analysis of decision paths for individual unseen instances in a random forest model\n",
    "* Frequent Pattern Mining of decision paths\n",
    "* Rule Compression of decision paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from forest_surveyor.plotting import rule_profile_plots\n",
    "i = 4\n",
    "alpha_scores = 0.75\n",
    "rule_profile_plots(rule_acc[i], ds.rcdv_samp_data().class_names, ig=False, cp=True, alpha_scores=alpha_scores)\n",
    "\n",
    "[results[i][ra].pruned_rule for ra in range(6)]\n",
    "[results[r][ra].pruned_rule for r in range(len(results)) for ra in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Global Explanations\n",
    "## Statistical Analysis of a random forest model using data batches\n",
    "* Inductive Properties are based on the training data\n",
    "* Transductive Properties are based on the test (held out) data\n",
    "* In both cases, the whole dataset is passed into the model and statistics are gathered about how frequently the features are visited.\n",
    "\n",
    "* OOB data (to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run the full forest survey\n",
    "tt_correct_stats, tt_incorrect_stats = cor_incor_forest_survey(\n",
    " f_walker = f_walker, X=tt['X_test'], y=tt['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_path_lengths(forest_stats=tt_correct_stats, class_names=mydata.class_names)\n",
    "plot_mean_path_lengths(forest_stats=tt_incorrect_stats, class_names=mydata.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_varimp(rf, mydata.onehot_features)\n",
    "plot_feature_stats(tt_correct_stats, 'p_root_traversals', mydata.class_names, mydata.onehot_features)\n",
    "plot_feature_stats(tt_correct_stats, 'p_child_traversals', mydata.class_names, mydata.onehot_features)\n",
    "plot_feature_stats(tt_correct_stats, 'p_lower_traversals', mydata.class_names, mydata.onehot_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_ratio = log_ratio_plot(num = tt_correct_stats[0]['m_child_traversals']\n",
    "                            , num_err = tt_correct_stats[0]['se_child_traversals']\n",
    "                            , denom = tt_incorrect_stats[0]['m_child_traversals']\n",
    "                            , denom_err = tt_incorrect_stats[0]['se_child_traversals']\n",
    "                            , labels = mydata.onehot_features\n",
    ")\n",
    "log_ratio = log_ratio_plot(num = tt_correct_stats[0]['m_lower_traversals']\n",
    "                            , num_err = tt_correct_stats[0]['se_lower_traversals']\n",
    "                            , denom = tt_incorrect_stats[0]['m_lower_traversals']\n",
    "                            , denom_err = tt_incorrect_stats[0]['se_lower_traversals']\n",
    "                            , labels = mydata.onehot_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Other Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## treeinterpreter - local explanations from conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti, utils\n",
    "prediction, bias, contributions = ti.predict(rf, encoder.transform(batch[instance:instance + 1]))\n",
    "\n",
    "interp_cols = sum([['predictor'], class_names, ['abseff']], [])\n",
    "interp = pd.DataFrame(columns=interp_cols)\n",
    "# now extract contributions for each instance\n",
    "for c, feature in zip(contributions[0], onehot_features):\n",
    "    if any(c != 0):\n",
    "        vals = c.tolist()\n",
    "        vals.insert(0, feature)\n",
    "        vals.append(sum(abs(c)))\n",
    "        interp = interp.append(dict(zip(interp_cols, vals))\n",
    "                               , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interp = interp.sort_values('abseff', ascending=False).reset_index().drop('index', axis=1)\n",
    "interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interp = interp.sort_values('bad', ascending=False).reset_index().drop('index', axis=1)\n",
    "interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "priors = dict(zip(interp_cols[1:],  np.append(bias[0], 1.0)))\n",
    "priors['predictor'] = 'priors (bias)'\n",
    "totals = dict(zip(interp_cols[1:],  interp.sum()[1:].values))\n",
    "totals['predictor'] = 'Total'\n",
    "preds = dict(zip(interp_cols[1:],  np.append(prediction, 1.0)))\n",
    "preds['predictor'] = 'P(class)'\n",
    "interp_totals = pd.DataFrame(columns=interp_cols)\n",
    "interp_totals = interp_totals.append(priors, ignore_index=True)\n",
    "\n",
    "interp_totals = interp_totals.append(totals, ignore_index=True)\n",
    "interp_totals = interp_totals.append(preds, ignore_index=True)\n",
    "interp_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# basic setup\n",
    "import lime\n",
    "import lime.lime_tabular as limtab\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "explainer = limtab.LimeTabularExplainer(training_data=np.array(X_train_enc.todense())\n",
    "                                        , feature_names=onehot_features\n",
    "                                        , training_labels=y_train\n",
    "                                        , class_names=class_names\n",
    "                                        , categorical_features=range(len(onehot_features))\n",
    "                                        , categorical_names=onehot_features\n",
    "                                        , mode='classification'\n",
    "                                        , discretize_continuous=False\n",
    "                                        , verbose=False)\n",
    "\n",
    "exp = explainer.explain_instance(np.array(encoder.transform(batch[instance:instance+1]).todense())[0]\n",
    "                                 , rf.predict_proba\n",
    "                                 , top_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = exp.as_pyplot_figure(label=pred_class_code)\n",
    "\n",
    "exp.as_list(label=pred_class_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show the runner up class details\n",
    "fig = exp.as_pyplot_figure(label=second_class_code)\n",
    "exp.as_list(label=second_class_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run whiteboxing_exp1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
